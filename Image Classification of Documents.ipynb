{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification of Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "To prepare your environment, you need to install some packages and enter credentials for the Watson services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Install the necessary packages\n",
    "You need the latest versions of these packages:\n",
    "python-swiftclient: is a python client for the Swift API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install IBM Cloud Object Storage Client: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ibm-cos-sdk in /Users/guixax/opt/anaconda3/lib/python3.8/site-packages (2.12.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.10.0 in /Users/guixax/opt/anaconda3/lib/python3.8/site-packages (from ibm-cos-sdk) (0.10.0)\n",
      "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.12.0 in /Users/guixax/opt/anaconda3/lib/python3.8/site-packages (from ibm-cos-sdk) (2.12.0)\n",
      "Requirement already satisfied: ibm-cos-sdk-core==2.12.0 in /Users/guixax/opt/anaconda3/lib/python3.8/site-packages (from ibm-cos-sdk) (2.12.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.26.9 in /Users/guixax/opt/anaconda3/lib/python3.8/site-packages (from ibm-cos-sdk-core==2.12.0->ibm-cos-sdk) (1.26.12)\n",
      "Requirement already satisfied: requests<3.0,>=2.27.1 in /Users/guixax/opt/anaconda3/lib/python3.8/site-packages (from ibm-cos-sdk-core==2.12.0->ibm-cos-sdk) (2.28.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /Users/guixax/opt/anaconda3/lib/python3.8/site-packages (from ibm-cos-sdk-core==2.12.0->ibm-cos-sdk) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/guixax/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.8.2->ibm-cos-sdk-core==2.12.0->ibm-cos-sdk) (1.15.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/guixax/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0,>=2.27.1->ibm-cos-sdk-core==2.12.0->ibm-cos-sdk) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/guixax/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0,>=2.27.1->ibm-cos-sdk-core==2.12.0->ibm-cos-sdk) (2020.12.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/guixax/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0,>=2.27.1->ibm-cos-sdk-core==2.12.0->ibm-cos-sdk) (2.10)\n",
      "Collecting botocore\n",
      "  Downloading botocore-1.27.90-py3-none-any.whl (9.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.2 MB 10.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/guixax/opt/anaconda3/lib/python3.8/site-packages (from botocore) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /Users/guixax/opt/anaconda3/lib/python3.8/site-packages (from botocore) (1.26.12)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/guixax/opt/anaconda3/lib/python3.8/site-packages (from botocore) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/guixax/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.15.0)\n",
      "Installing collected packages: botocore\n",
      "Successfully installed botocore-1.27.90\n"
     ]
    }
   ],
   "source": [
    "!pip install ibm-cos-sdk\n",
    "!pip install botocore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now restart the kernel by choosing Kernel > Restart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Import packages and libraries\n",
    "Import the packages and libraries that you'll use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'RMSprop' from 'keras.optimizers' (/Users/guixax/opt/anaconda3/lib/python3.8/site-packages/keras/optimizers.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-dface6f148e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRMSprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'RMSprop' from 'keras.optimizers' (/Users/guixax/opt/anaconda3/lib/python3.8/site-packages/keras/optimizers.py)"
     ]
    }
   ],
   "source": [
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import keras\n",
    "import itertools\n",
    "from PIL import Image\n",
    "import ibm_boto3\n",
    "from botocore.client import Config\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from skimage import feature, data, io, measure\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Conv2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "Add configurable items of the notebook below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Add your service credentials for Object Storage\n",
    "You must create Object Storage service on IBM Cloud. To access data in a file in Object Storage, you need the Object Storage authentication credentials. Insert the Object Storage Streaming Body credentials and ensure the variable is referred as  streaming_body_1 in the following cell after removing the current contents in the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Global Variables \n",
    "Enter the batch size for training, testing and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 20\n",
    "batch_size_val = 10\n",
    "batch_size_test = 25\n",
    "num_classes= 5\n",
    "intereseted_folder='Documents'\n",
    "STANDARD_SIZE=(224,224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Storage\n",
    "\n",
    "## 3.1 Extract the Dataset \n",
    "\n",
    "Input the zip file from object storage and extract the data onto the /home/dsxuser/work folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import zipfile\n",
    "\n",
    "zip_ref = zipfile.ZipFile(BytesIO(streaming_body_1.read()),'r')\n",
    "paths = zip_ref.namelist()\n",
    "classes_required=[]\n",
    "for path in paths:\n",
    "    zip_ref.extract(path)\n",
    "    temp=path.split('/')\n",
    "    if len(temp) > 3:\n",
    "        if temp[2] not in classes_required:\n",
    "            classes_required.append(temp[2])\n",
    "print(classes_required)\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Classification\n",
    "\n",
    "## 4.1 Create the Datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Converting Data Format according to the backend used by Keras\n",
    "'''\n",
    "datagen=keras.preprocessing.image.ImageDataGenerator(data_format=K.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Input the Training Data\n",
    "'''\n",
    "train_path = '/home/dsxuser/work/Data/Train_Data/'\n",
    "train_batches = ImageDataGenerator().flow_from_directory(train_path, target_size=(224,224), classes=classes_required, batch_size=batch_size_train)\n",
    "type(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Input the Validation Data\n",
    "'''\n",
    "\n",
    "val_path = '/home/dsxuser/work/Data/Val_Data/'\n",
    "val_batches = ImageDataGenerator().flow_from_directory(val_path, target_size=(224,224), classes=classes_required, batch_size=batch_size_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Input the Test Data\n",
    "'''\n",
    "test_path = '/home/dsxuser/work/Data/Test_Data/'\n",
    "test_batches = ImageDataGenerator().flow_from_directory(test_path, target_size=(224,224), classes=classes_required, batch_size=batch_size_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs, test_labels = next(test_batches)\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test= [ np.where(r==1)[0][0] for r in test_labels ]\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The below cell may take 5 mins to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = keras.applications.vgg16.VGG16()\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(vgg16_model) #This is a Keras Functional API need to convert to sequential\n",
    "model = Sequential() #Iterate over the functional layers and add it as a stack\n",
    "for layer in vgg16_model.layers:\n",
    "    model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers.pop()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers: #Since the model is already trained with certain weights, we dont want to change it. Let it be the same\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(5, activation='sigmoid')) # Add the last layer\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complie the model\n",
    "model.compile(Adam(lr=.00015), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Train the Model\n",
    "\n",
    "The model will take about 30-45 minutes to train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_batches, steps_per_epoch=20, \n",
    "                    validation_data=val_batches, validation_steps=20, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Test the Model with External Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('my_model_weights.h5')\n",
    "#model.load_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import zipfile\n",
    "\n",
    "zip_ref = zipfile.ZipFile(BytesIO(streaming_body_2.read()),'r')\n",
    "paths = zip_ref.namelist()\n",
    "del paths[0]\n",
    "print(paths)\n",
    "for path in paths:\n",
    "    print(zip_ref.extract(path))\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=[]\n",
    "def convert_to_image(X):\n",
    "    '''Function to convert all Input Images to the STANDARD_SIZE and create Training Dataset\n",
    "    '''\n",
    "    for f in paths:\n",
    "        #fobj=get_file(f)\n",
    "        #print(type(fobj))predictions= model.predict(X_test)\n",
    "        if os.path.isdir(f):\n",
    "            continue\n",
    "        img= PIL.Image.open(f)\n",
    "        img = img.resize(STANDARD_SIZE)\n",
    "        img=np.array(img)\n",
    "        X.append(img)\n",
    "        #print(X_train)\n",
    "    #print(len(X_train))\n",
    "    return X\n",
    "X_test=np.array(convert_to_image(X_test))\n",
    "datagen.fit(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= model.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "for i in range(len(predictions)):\n",
    "    y_pred.append(np.argmax(predictions[i]))\n",
    "y_pred\n",
    "j = 0\n",
    "for i in y_pred:\n",
    "    print(paths[y_pred[j]])\n",
    "    j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(classes_required)\n",
    "index= classes_required.index('Documents')\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == index:\n",
    "        print(\"Image classified as a form document: \", paths[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Accuracy Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_batches, steps=1, verbose=0)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions\n",
    "y_pred=[]\n",
    "for i in range(len(predictions)):\n",
    "    y_pred.append(np.argmax(predictions[i]))\n",
    "print(y_pred)\n",
    "#plots(test_imgs, titles=y_pred)\n",
    "\n",
    "ctr=0\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == y_test[i]:\n",
    "        ctr=ctr+1\n",
    "res = ctr/len(y_pred)*100\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "144f974373c9fda24aaee5df054dd1f07b7d95d6200df4c599d8b429227f40a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
